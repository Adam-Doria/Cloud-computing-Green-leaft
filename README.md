# üìò GreenLeaf : Guide d'Architecture & Impl√©mentation

## 1. Vue d'Ensemble de l'Architecture
Nous d√©ployons une architecture **Hybride (Multi-Cloud)** et **Haute Disponibilit√© (HA)** con√ßue pour tenir un trafic e-commerce tout en respectant un budget strict de 500$/mois.

### üó∫Ô∏è Le Flux de Donn√©es (Request Flow)
1.  **Utilisateur** : Tape `greenleaf.com`.
2.  **Cloudflare (Edge)** :
    *   Re√ßoit la requ√™te.
    *   V√©rifie la s√©curit√© (WAF/DDoS).
    *   Sert le contenu statique (Images, CSS) depuis son cache.
    *   *Si c'est une image produit* : La sert directement depuis le bucket **R2**.
    *   *Si c'est du dynamique* : Transf√®re la requ√™te vers AWS.
3.  **AWS Load Balancer (ALB)** : Re√ßoit le trafic filtr√© sur le port 80.
4.  **Auto Scaling Group (Compute)** :
    *   L'ALB choisit l'instance la moins charg√©e (Zone A ou Zone B).
    *   **Caddy (Reverse Proxy)** re√ßoit la requ√™te sur l'instance.
    *   Caddy la passe au conteneur **Medusa Backend** ou **Storefront**.
5.  **Donn√©es & Persistance** :
    *   Medusa lit/√©crit dans **RDS PostgreSQL** (Donn√©es clients).
    *   Medusa stocke la session dans **Redis** (Cache partag√©).
    *   Pour sortir sur Internet (ex: Stripe), Medusa passe par la **NAT Instance**.

---

## 2. R√¥les des Outils (Qui fait quoi ?)

C'est ici qu'on √©vite la confusion.

### üèóÔ∏è Terraform : Le Ma√ßon (Infrastructure Provisioning)
Terraform construit les "murs" de la maison. Il parle √† l'API AWS.
*   **Ce qu'il g√®re :**
    *   Le r√©seau (VPC, Subnets, Route Tables).
    *   Les services manag√©s (RDS, ElastiCache, ALB).
    *   Les r√®gles de s√©curit√© (Security Groups).
    *   Les d√©finitions de scaling (Auto Scaling Group, Launch Template).
*   **Commandes cl√©s :** `terraform plan`, `terraform apply`.

### üõ†Ô∏è Ansible / User Data : L'√âlectricien & D√©corateur (Configuration Management)
Une fois les murs construits (EC2 lanc√©e), il faut installer les logiciels.
*   **Ce qu'il g√®re :**
    *   Mise √† jour Linux (`dnf update`).
    *   Installation de **Docker** et **Docker Compose**.
    *   Cr√©ation des fichiers de configuration (`.env`).
    *   Lancement de l'application.
*   **Impl√©mentation GreenLeaf :**
    *   Pour gagner du temps, nous n'utiliserons pas un serveur Ansible ma√Ætre complexe.
    *   Nous injecterons un script **Bash** (via le `user_data` Terraform) qui agit comme un playbook Ansible local au d√©marrage de chaque instance.

### ‚òÅÔ∏è Cloudflare : Le Vigile & L'Entrep√¥t
*   **S√©curit√© :** Bloque les attaques avant qu'elles ne touchent AWS (et ne co√ªtent de l'argent).
*   **Stockage (R2) :** Remplace AWS S3.
    *   *Avantage :* 0 $ de frais de sortie (Egress fees). Sur AWS, t√©l√©charger des images co√ªte cher. Sur Cloudflare R2, c'est gratuit.

---

## 3. Impl√©mentation √âtape par √âtape

### Phase A : Le R√©seau & FinOps (Le Socle)
*Le plus gros d√©fi technique, mais la plus grosse √©conomie.*

1.  **VPC Multi-AZ :** Cr√©ation d'un r√©seau sur Paris (`eu-west-3`) avec 2 AZ.
2.  **L'Astuce NAT Instance :**
    *   Normalement, AWS vend des "NAT Gateways" (66$/mois) pour que les serveurs priv√©s acc√®dent √† internet.
    *   **Nous d√©ployons 2 petites instances EC2 `t3.nano`** (une par zone).
    *   Nous les configurons en routeurs (`iptables -t nat -A POSTROUTING -j MASQUERADE`).
    *   **Co√ªt :** ~8$/mois.
    *   **Terraform :** On configure les `aws_route_table` des sous-r√©seaux priv√©s pour utiliser l'ID de ces instances comme passerelle `0.0.0.0/0`.

### Phase B : La Data (Le Coffre-fort)
*Les donn√©es ne doivent jamais √™tre perdues.*

1.  **RDS PostgreSQL :**
    *   D√©ploy√© dans les sous-r√©seaux priv√©s "Data".
    *   En **PROD** : `multi_az = true`. Une copie synchrone est faite dans l'autre zone.
    *   Security Group : N'accepte que le port 5432 venant des instances App.
2.  **ElastiCache Redis :**
    *   Stocke les sessions utilisateurs. Si une instance App meurt, l'utilisateur ne est pas d√©connect√© car sa session est dans Redis.
    *   Type : `cache.t3.micro` (Suffisant et pas cher).

### Phase C : L'Application (Le Moteur)
*Dockerisation pour la portabilit√©.*

1.  **L'Image Docker :**
    *   On construit une image pour le Backend (API) et une pour le Storefront (Next.js).
    *   On utilise **Caddy** dans le `docker-compose.yml` comme chef d'orchestre local.
2.  **Int√©gration R2 (Stockage Images) :**
    *   Dans Medusa, on installe le plugin `medusa-file-s3`.
    *   On le configure avec l'endpoint S3 de Cloudflare : `https://<account_id>.r2.cloudflarestorage.com`.
    *   R√©sultat : Quand l'admin upload une photo produit, elle part direct chez Cloudflare, pas sur le disque du serveur.

### Phase D : Le Scaling (L'√âlasticit√©)

1.  **Launch Template :**
    *   C'est le "moule" des serveurs. Il contient le script de d√©marrage (`user_data`).
    *   Le script fait : `Install Docker` -> `Git Clone` -> `Docker Compose Up`.
2.  **Auto Scaling Group (ASG) :**
    *   Il surveille le CPU.
    *   Si CPU > 60% : Il cr√©e une nouvelle instance √† partir du moule.
    *   Si CPU < 40% : Il tue une instance.
3.  **Application Load Balancer (ALB) :**
    *   C'est le point d'entr√©e unique.
    *   L'ASG enregistre automatiquement les nouvelles instances dans l'ALB.

---

## 4. Strat√©gie FinOps (Comment on tient les 500$)

C'est ce qui vous donnera la note maximale.

### 1. Architecture NAT "Low-Cost"
*   **Gain :** ~58 $ / mois.
*   **Technique :** Remplacement des NAT Gateways manag√©es par des instances EC2 `t3.nano` Linux configur√©es manuellement.

### 2. Le "Scheduler" Preprod
*   **Gain :** ~70 % sur la facture Preprod.
*   **Technique :**
    *   L'environnement de Preprod est identique √† la Prod (Multi-AZ, RDS, ALB).
    *   **Mais** un script Terraform (`aws_autoscaling_schedule`) √©teint tout (Desired Capacity = 0) tous les soirs √† 19h et le rallume √† 9h.
    *   On ne paie pas pour des serveurs qui dorment.

### 3. Cloudflare R2 vs S3
*   **Gain :** Variable (selon trafic), mais √©limine le risque de d√©passement "Data Transfer Out".
*   **Technique :** Utilisation du stockage objet Cloudflare qui ne facture pas la bande passante sortante.

### 4. Instances Spot en DEV
*   **Gain :** ~60-70% sur le compute Dev.
*   **Technique :** L'environnement de Dev utilise des instances "Spot" (ench√®res sur la capacit√© inutilis√©e d'AWS).

---

## 5. Guide de Survie : Commandes Utiles

### Initialiser le projet
```bash
# 1. Configurer les variables d'environnement AWS
export AWS_ACCESS_KEY_ID="AKIA..."
export AWS_SECRET_ACCESS_KEY="secret..."

# 2. Bootstrap (Cr√©er le bucket d'√©tat S3 une seule fois)
./scripts/bootstrap.sh

# 3. Initialiser Terraform
cd terraform
terraform init
```

### D√©ployer la PROD
```bash
# Toujours v√©rifier avant de casser
terraform plan -var-file="envs/prod.tfvars"

# Appliquer
terraform apply -var-file="envs/prod.tfvars"
```

### D√©ployer la DEV (Low Cost)
```bash
# Changer de workspace
terraform workspace new dev || terraform workspace select dev

# Appliquer la config light
terraform apply -var-file="envs/dev.tfvars"
```

### Se connecter √† une instance priv√©e (Debug)
Comme les instances sont priv√©es, on passe par le "Session Manager" (SSM) ou on utilise la NAT instance comme bastion (si configur√©).
*Recommand√© :* Utiliser AWS SSM (d√©j√† install√© sur Amazon Linux 2).
```bash
aws ssm start-session --target i-0123456789abcdef0
```

